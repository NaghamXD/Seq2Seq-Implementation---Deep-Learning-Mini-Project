{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8917dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from datasets import load_dataset\n",
    "from torchmetrics.functional.text import bleu_score\n",
    "import spacy\n",
    "\n",
    "# Load Spacy\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# --- 1. VOCABULARY CLASS ---\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold=2, max_size=80000):\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_eng(text):\n",
    "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_fr(text):\n",
    "        return [tok.text.lower() for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "    def build_vocabulary(self, sentence_list, tokenizer):\n",
    "        frequencies = Counter()\n",
    "        idx = 4\n",
    "        for sentence in sentence_list:\n",
    "            for word in tokenizer(sentence):\n",
    "                frequencies[word] += 1\n",
    "        common_words = frequencies.most_common(self.max_size - 4)\n",
    "        for word, count in common_words:\n",
    "            if count >= self.freq_threshold:\n",
    "                self.stoi[word] = idx\n",
    "                self.itos[idx] = word\n",
    "                idx += 1\n",
    "\n",
    "    def numericalize(self, text, tokenizer):\n",
    "        tokenized_text = tokenizer(text)\n",
    "        return [self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokenized_text]\n",
    "\n",
    "# --- 2. DATASET CLASS (WITH REVERSING) ---\n",
    "class WMT14Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, source_vocab, target_vocab):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pair = self.hf_dataset[index]['translation']\n",
    "        src_text = pair['en']\n",
    "        trg_text = pair['fr']\n",
    "\n",
    "        # Numericalize and REVERSE Source\n",
    "        src_indices = self.source_vocab.numericalize(src_text, self.source_vocab.tokenizer_eng)\n",
    "        src_indices = src_indices[::-1] # <--- REVERSING INPUT HERE\n",
    "        \n",
    "        numericalized_source = [self.source_vocab.stoi[\"<SOS>\"]] + src_indices + [self.source_vocab.stoi[\"<EOS>\"]]\n",
    "        numericalized_target = [self.target_vocab.stoi[\"<SOS>\"]] + \\\n",
    "                               self.target_vocab.numericalize(trg_text, self.target_vocab.tokenizer_fr) + \\\n",
    "                               [self.target_vocab.stoi[\"<EOS>\"]]\n",
    "\n",
    "        return torch.tensor(numericalized_source), torch.tensor(numericalized_target)\n",
    "\n",
    "class MyCollate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "    def __call__(self, batch):\n",
    "        source = [item[0] for item in batch]\n",
    "        target = [item[1] for item in batch]\n",
    "        source = pad_sequence(source, batch_first=False, padding_value=self.pad_idx)\n",
    "        target = pad_sequence(target, batch_first=False, padding_value=self.pad_idx)\n",
    "        return source, target\n",
    "\n",
    "# --- 3. MODEL ARCHITECTURE ---\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if random.random() < teacher_forcing_ratio else top1\n",
    "        return outputs\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43f30f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f08316dec9244359d3e4b73c6c0fc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e78290ede044780adf6fe92b746ca11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocabularies...\n",
      "Unique English Words: 10731\n",
      "Unique French Words: 14472\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "BATCH_SIZE = 32\n",
    "SUBSET_SIZE = 10000\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using Device: {DEVICE}\")\n",
    "\n",
    "# 1. Load Data\n",
    "dataset = load_dataset(\"wmt14\", \"fr-en\")\n",
    "train_subset = dataset['train'].select(range(SUBSET_SIZE))\n",
    "valid_subset = dataset['validation'].select(range(1000))\n",
    "\n",
    "# 2. Build Vocab\n",
    "print(\"Building Vocabularies...\")\n",
    "vocab_en = Vocabulary(freq_threshold=1, max_size=80000)\n",
    "vocab_en.build_vocabulary([item['translation']['en'] for item in train_subset], vocab_en.tokenizer_eng)\n",
    "\n",
    "vocab_fr = Vocabulary(freq_threshold=1, max_size=80000)\n",
    "vocab_fr.build_vocabulary([item['translation']['fr'] for item in train_subset], vocab_fr.tokenizer_fr)\n",
    "\n",
    "print(f\"Unique English Words: {len(vocab_en)}\")\n",
    "print(f\"Unique French Words: {len(vocab_fr)}\")\n",
    "\n",
    "# 3. DataLoaders\n",
    "pad_idx = vocab_en.stoi[\"<PAD>\"]\n",
    "train_loader = DataLoader(\n",
    "    WMT14Dataset(train_subset, vocab_en, vocab_fr),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=MyCollate(pad_idx)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3659175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "TRAINING MODEL 1/5 (Seed: 1)\n",
      "====================\n",
      "Seed 1 | Epoch 1 | Loss: 6.703 | PPL: 814.91\n",
      "Seed 1 | Epoch 2 | Loss: 6.408 | PPL: 606.40\n",
      "Seed 1 | Epoch 3 | Loss: 6.315 | PPL: 553.00\n",
      "Seed 1 | Epoch 4 | Loss: 6.272 | PPL: 529.49\n",
      "Seed 1 | Epoch 5 | Loss: 6.253 | PPL: 519.52\n",
      "Seed 1 | Epoch 6 | Loss: 6.212 | PPL: 498.53\n",
      "Seed 1 | Epoch 7 | Loss: 6.197 | PPL: 491.13\n",
      "Seed 1 | Epoch 8 | Loss: 6.190 | PPL: 488.07\n",
      "--> Saved model_seed_1.pt\n",
      "\n",
      "====================\n",
      "TRAINING MODEL 2/5 (Seed: 2)\n",
      "====================\n",
      "Seed 2 | Epoch 1 | Loss: 6.709 | PPL: 819.88\n",
      "Seed 2 | Epoch 2 | Loss: 6.402 | PPL: 603.22\n",
      "Seed 2 | Epoch 3 | Loss: 6.310 | PPL: 549.95\n",
      "Seed 2 | Epoch 4 | Loss: 6.273 | PPL: 530.30\n",
      "Seed 2 | Epoch 5 | Loss: 6.253 | PPL: 519.66\n",
      "Seed 2 | Epoch 6 | Loss: 6.214 | PPL: 499.47\n",
      "Seed 2 | Epoch 7 | Loss: 6.201 | PPL: 493.25\n",
      "Seed 2 | Epoch 8 | Loss: 6.193 | PPL: 489.09\n",
      "--> Saved model_seed_2.pt\n",
      "\n",
      "====================\n",
      "TRAINING MODEL 3/5 (Seed: 3)\n",
      "====================\n",
      "Seed 3 | Epoch 1 | Loss: 6.712 | PPL: 821.81\n",
      "Seed 3 | Epoch 2 | Loss: 6.391 | PPL: 596.40\n",
      "Seed 3 | Epoch 3 | Loss: 6.297 | PPL: 542.87\n",
      "Seed 3 | Epoch 4 | Loss: 6.265 | PPL: 525.75\n",
      "Seed 3 | Epoch 5 | Loss: 6.248 | PPL: 517.00\n",
      "Seed 3 | Epoch 6 | Loss: 6.207 | PPL: 496.43\n",
      "Seed 3 | Epoch 7 | Loss: 6.194 | PPL: 489.60\n",
      "Seed 3 | Epoch 8 | Loss: 6.186 | PPL: 486.13\n",
      "--> Saved model_seed_3.pt\n",
      "\n",
      "====================\n",
      "TRAINING MODEL 4/5 (Seed: 4)\n",
      "====================\n",
      "Seed 4 | Epoch 1 | Loss: 6.709 | PPL: 819.53\n",
      "Seed 4 | Epoch 2 | Loss: 6.409 | PPL: 607.45\n",
      "Seed 4 | Epoch 3 | Loss: 6.359 | PPL: 577.71\n",
      "Seed 4 | Epoch 4 | Loss: 6.329 | PPL: 560.62\n",
      "Seed 4 | Epoch 5 | Loss: 6.283 | PPL: 535.45\n",
      "Seed 4 | Epoch 6 | Loss: 6.223 | PPL: 504.13\n",
      "Seed 4 | Epoch 7 | Loss: 6.200 | PPL: 492.81\n",
      "Seed 4 | Epoch 8 | Loss: 6.193 | PPL: 489.47\n",
      "--> Saved model_seed_4.pt\n",
      "\n",
      "====================\n",
      "TRAINING MODEL 5/5 (Seed: 5)\n",
      "====================\n",
      "Seed 5 | Epoch 1 | Loss: 6.707 | PPL: 818.51\n",
      "Seed 5 | Epoch 2 | Loss: 6.405 | PPL: 604.71\n",
      "Seed 5 | Epoch 3 | Loss: 6.360 | PPL: 578.37\n",
      "Seed 5 | Epoch 4 | Loss: 6.334 | PPL: 563.62\n",
      "Seed 5 | Epoch 5 | Loss: 6.276 | PPL: 531.75\n",
      "Seed 5 | Epoch 6 | Loss: 6.216 | PPL: 500.49\n",
      "Seed 5 | Epoch 7 | Loss: 6.201 | PPL: 493.02\n",
      "Seed 5 | Epoch 8 | Loss: 6.193 | PPL: 489.47\n",
      "--> Saved model_seed_5.pt\n",
      "\n",
      "All 5 models trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- HYPERPARAMETERS ---\n",
    "INPUT_DIM = len(vocab_en)\n",
    "OUTPUT_DIM = len(vocab_fr)\n",
    "ENC_EMB_DIM = 1000\n",
    "DEC_EMB_DIM = 1000\n",
    "HID_DIM = 1000\n",
    "N_LAYERS = 4\n",
    "DROPOUT = 0.2\n",
    "N_EPOCHS = 8 \n",
    "CLIP = 5\n",
    "\n",
    "SEEDS = [1, 2, 3, 4, 5]\n",
    "\n",
    "def train_one_epoch(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# --- TRAINING LOOP FOR 5 MODELS ---\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*20}\")\n",
    "    print(f\"TRAINING MODEL {seed}/5 (Seed: {seed})\")\n",
    "    print(f\"{'='*20}\")\n",
    "    \n",
    "    # 1. Set Seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.mps.is_available(): torch.mps.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # 2. Initialize Fresh Model\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
    "    model.apply(init_weights) # Paper initialization\n",
    "    \n",
    "    # 3. Optimizer & Criterion\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.7)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "    \n",
    "    # 4. Train\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        # Halve LR after epoch 5 (Simplified schedule)\n",
    "        if epoch >= 5:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = param_group['lr'] * 0.5\n",
    "        \n",
    "        loss = train_one_epoch(model, train_loader, optimizer, criterion, CLIP)\n",
    "        print(f\"Seed {seed} | Epoch {epoch+1} | Loss: {loss:.3f} | PPL: {math.exp(loss):.2f}\")\n",
    "        \n",
    "    # 5. Save Model\n",
    "    save_path = f\"model_seed_{seed}.pt\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"--> Saved {save_path}\")\n",
    "\n",
    "print(\"\\nAll 5 models trained and saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c31929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decode_ensemble(models_list, sentence, vocab_src, vocab_trg, beam_size=2, max_len=50, device='cpu'):\n",
    "    # Ensure models are in eval mode\n",
    "    for m in models_list: m.eval()\n",
    "    \n",
    "    # Prepare Input\n",
    "    if isinstance(sentence, str): tokens = vocab_src.tokenizer_eng(sentence)\n",
    "    else: tokens = [token.lower() for token in sentence]\n",
    "    \n",
    "    indices = [vocab_src.stoi.get(t, vocab_src.stoi[\"<UNK>\"]) for t in tokens]\n",
    "    indices = indices[::-1] # REVERSE\n",
    "    indices = [vocab_src.stoi[\"<SOS>\"]] + indices + [vocab_src.stoi[\"<EOS>\"]]\n",
    "    src_tensor = torch.LongTensor(indices).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encoder states for all models\n",
    "        initial_states = []\n",
    "        for m in models_list:\n",
    "            h, c = m.encoder(src_tensor)\n",
    "            initial_states.append((h, c))\n",
    "\n",
    "        hypotheses = [(0.0, [vocab_trg.stoi[\"<SOS>\"]], initial_states)]\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            all_candidates = []\n",
    "            for score, seq, states_list in hypotheses:\n",
    "                if seq[-1] == vocab_trg.stoi[\"<EOS>\"]:\n",
    "                    all_candidates.append((score, seq, states_list))\n",
    "                    continue\n",
    "                \n",
    "                last_token = torch.LongTensor([seq[-1]]).to(device)\n",
    "                \n",
    "                # Run all models and AVERAGE logits\n",
    "                avg_log_probs = None\n",
    "                new_states_list = []\n",
    "                for i, m in enumerate(models_list):\n",
    "                    prev_h, prev_c = states_list[i]\n",
    "                    pred, new_h, new_c = m.decoder(last_token, prev_h, prev_c)\n",
    "                    new_states_list.append((new_h, new_c))\n",
    "                    \n",
    "                    # --- FIX START ---\n",
    "                    # Squeeze the batch dimension: [1, vocab_size] -> [vocab_size]\n",
    "                    pred = pred.squeeze(0)\n",
    "                    # --- FIX END ---\n",
    "\n",
    "                    log_probs = F.log_softmax(pred, dim=0)\n",
    "                    if avg_log_probs is None: avg_log_probs = log_probs\n",
    "                    else: avg_log_probs += log_probs\n",
    "                \n",
    "                avg_log_probs = avg_log_probs / len(models_list)\n",
    "                top_k_probs, top_k_ids = avg_log_probs.topk(beam_size * 2)\n",
    "\n",
    "                for i in range(len(top_k_ids)):\n",
    "                    all_candidates.append((score + top_k_probs[i].item(), seq + [top_k_ids[i].item()], new_states_list))\n",
    "\n",
    "            hypotheses = sorted(all_candidates, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "            if all(h[1][-1] == vocab_trg.stoi[\"<EOS>\"] for h in hypotheses): break\n",
    "\n",
    "    best_seq = hypotheses[0][1]\n",
    "    decoded_words = [vocab_trg.itos[idx] for idx in best_seq]\n",
    "    if \"<SOS>\" in decoded_words: decoded_words.remove(\"<SOS>\")\n",
    "    if \"<EOS>\" in decoded_words: decoded_words = decoded_words[:decoded_words.index(\"<EOS>\")]\n",
    "    return \" \".join(decoded_words)\n",
    "\n",
    "# --- BLEU EVALUATOR ---\n",
    "def evaluate_ensemble(data_subset, models_list, vocab_src, vocab_trg, device, beam_size):\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    print(f\"Evaluating Ensemble on {len(data_subset)} samples...\")\n",
    "    \n",
    "    for i, datum in enumerate(data_subset):\n",
    "        if (i+1)%50 == 0: print(f\"Processed {i+1}...\")\n",
    "        pair = datum['translation']\n",
    "        pred = beam_search_decode_ensemble(     \n",
    "                models_list, \n",
    "                pair['en'], \n",
    "                vocab_src, \n",
    "                vocab_trg, \n",
    "                beam_size, \n",
    "                max_len=50, # Optional: Explicitly set max_len here if you want\n",
    "                device=device\n",
    "            )\n",
    "        targets.append([pair['fr']])\n",
    "        predictions.append(pred)\n",
    "        \n",
    "    return bleu_score(predictions, targets, n_gram=4).item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6be9cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ensemble Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/jsd5qxh15h774sg5vyn663yh0000gn/T/ipykernel_26255/1231834882.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  m.load_state_dict(torch.load(f\"model_seed_{seed}.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model_seed_1.pt\n",
      "Loaded model_seed_2.pt\n",
      "Loaded model_seed_3.pt\n",
      "Loaded model_seed_4.pt\n",
      "Loaded model_seed_5.pt\n",
      "\n",
      "--- Manual Ensemble Check ---\n",
      "Input: the cat sat on the mat\n",
      "Output: le de de\n",
      "Evaluating Ensemble on 1000 samples...\n",
      "Processed 50...\n",
      "Processed 100...\n",
      "Processed 150...\n",
      "Processed 200...\n",
      "Processed 250...\n",
      "Processed 300...\n",
      "Processed 350...\n",
      "Processed 400...\n",
      "Processed 450...\n",
      "Processed 500...\n",
      "Processed 550...\n",
      "Processed 600...\n",
      "Processed 650...\n",
      "Processed 700...\n",
      "Processed 750...\n",
      "Processed 800...\n",
      "Processed 850...\n",
      "Processed 900...\n",
      "Processed 950...\n",
      "Processed 1000...\n",
      "\n",
      "=================================\n",
      "FINAL ENSEMBLE BLEU SCORE: 0.00\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the 5 Saved Models\n",
    "ensemble_models = []\n",
    "print(\"Loading Ensemble Models...\")\n",
    "\n",
    "for seed in SEEDS:\n",
    "    # Re-instantiate architecture\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "    m = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
    "    \n",
    "    # Load weights\n",
    "    m.load_state_dict(torch.load(f\"model_seed_{seed}.pt\"))\n",
    "    ensemble_models.append(m)\n",
    "    print(f\"Loaded model_seed_{seed}.pt\")\n",
    "\n",
    "# 2. Sanity Check\n",
    "print(\"\\n--- Manual Ensemble Check ---\")\n",
    "test_sen = \"the cat sat on the mat\"\n",
    "print(f\"Input: {test_sen}\")\n",
    "print(f\"Output: {beam_search_decode_ensemble(ensemble_models, test_sen, vocab_en, vocab_fr, beam_size=2, device=DEVICE)}\")\n",
    "\n",
    "# 3. Final BLEU Score\n",
    "final_score = evaluate_ensemble(valid_subset, ensemble_models, vocab_en, vocab_fr, DEVICE, beam_size=2)\n",
    "print(f\"\\n=================================\")\n",
    "print(f\"FINAL ENSEMBLE BLEU SCORE: {final_score:.2f}\")\n",
    "print(f\"=================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
