{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91624d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from datasets import load_dataset\n",
    "from torchmetrics.functional.text import bleu_score\n",
    "import spacy\n",
    "\n",
    "# Load Spacy\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "spacy_fr = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8917dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. VOCABULARY CLASS ---\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold=2, max_size=80000):\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_eng(text):\n",
    "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_fr(text):\n",
    "        return [tok.text.lower() for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "    def build_vocabulary(self, sentence_list, tokenizer):\n",
    "        frequencies = Counter()\n",
    "        idx = 4\n",
    "        for sentence in sentence_list:\n",
    "            for word in tokenizer(sentence):\n",
    "                frequencies[word] += 1\n",
    "        common_words = frequencies.most_common(self.max_size - 4)\n",
    "        for word, count in common_words:\n",
    "            if count >= self.freq_threshold:\n",
    "                self.stoi[word] = idx\n",
    "                self.itos[idx] = word\n",
    "                idx += 1\n",
    "\n",
    "    def numericalize(self, text, tokenizer):\n",
    "        tokenized_text = tokenizer(text)\n",
    "        return [self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokenized_text]\n",
    "\n",
    "# --- 2. DATASET CLASS (WITH REVERSING) ---\n",
    "class WMT14Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, source_vocab, target_vocab):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pair = self.hf_dataset[index]['translation']\n",
    "        src_text = pair['en']\n",
    "        trg_text = pair['fr']\n",
    "\n",
    "        # Numericalize and REVERSE Source\n",
    "        src_indices = self.source_vocab.numericalize(src_text, self.source_vocab.tokenizer_eng)\n",
    "        src_indices = src_indices[::-1] # <--- REVERSING INPUT HERE\n",
    "        \n",
    "        numericalized_source = [self.source_vocab.stoi[\"<SOS>\"]] + src_indices + [self.source_vocab.stoi[\"<EOS>\"]]\n",
    "        numericalized_target = [self.target_vocab.stoi[\"<SOS>\"]] + \\\n",
    "                               self.target_vocab.numericalize(trg_text, self.target_vocab.tokenizer_fr) + \\\n",
    "                               [self.target_vocab.stoi[\"<EOS>\"]]\n",
    "\n",
    "        return torch.tensor(numericalized_source), torch.tensor(numericalized_target)\n",
    "\n",
    "class MyCollate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "    def __call__(self, batch):\n",
    "        source = [item[0] for item in batch]\n",
    "        target = [item[1] for item in batch]\n",
    "        source = pad_sequence(source, batch_first=False, padding_value=self.pad_idx)\n",
    "        target = pad_sequence(target, batch_first=False, padding_value=self.pad_idx)\n",
    "        return source, target\n",
    "\n",
    "# --- 3. MODEL ARCHITECTURE ---\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if random.random() < teacher_forcing_ratio else top1\n",
    "        return outputs\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873ae115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BucketBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size, noise=0.1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.noise = noise # Adds a little randomness to the sorting so batches aren't identical every epoch\n",
    "        \n",
    "        # 1. Pre-calculate lengths of all source sentences\n",
    "        # (This takes a moment at startup but saves huge time during training)\n",
    "        print(\"Calculating dataset lengths for bucketing...\")\n",
    "        self.lengths = []\n",
    "        for i in range(len(dataset)):\n",
    "            # Access the raw text directly from the HF dataset to be fast\n",
    "            src_text = dataset.hf_dataset[i]['translation']['en']\n",
    "            self.lengths.append(len(src_text)) # approximate length by char count (faster) or use tokenizer\n",
    "            \n",
    "    def __iter__(self):\n",
    "        # 2. Create indices and add noise to lengths\n",
    "        # We add random noise to lengths so the sort order changes slightly every epoch\n",
    "        indices = list(range(len(self.dataset)))\n",
    "        \n",
    "        # Zip indices with their noisy lengths\n",
    "        noisy_lengths = [l + random.uniform(-self.noise, self.noise) for l in self.lengths]\n",
    "        indices_with_lens = list(zip(indices, noisy_lengths))\n",
    "        \n",
    "        # 3. Sort by length\n",
    "        indices_with_lens.sort(key=lambda x: x[1])\n",
    "        sorted_indices = [x[0] for x in indices_with_lens]\n",
    "        \n",
    "        # 4. Create batches\n",
    "        # Since the list is sorted, chunks of 'batch_size' will naturally have similar lengths\n",
    "        batches = [sorted_indices[i:i + self.batch_size] for i in range(0, len(sorted_indices), self.batch_size)]\n",
    "        \n",
    "        # 5. Shuffle the BATCHES (Important!)\n",
    "        # We want to train on similar-length sentences together, \n",
    "        # BUT we don't want to always train on short sentences first and long ones last.\n",
    "        random.shuffle(batches)\n",
    "        \n",
    "        # Yield one batch at a time\n",
    "        for batch in batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43f30f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a294552ca6347928d27a4daa2cdebef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd78d7bf31a418cbd214a03e380751f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocabularies...\n",
      "Unique English Words: 10731\n",
      "Unique French Words: 14472\n",
      "Calculating dataset lengths for bucketing...\n",
      "Optimized DataLoader ready.\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "BATCH_SIZE = 32\n",
    "SUBSET_SIZE = 10000\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using Device: {DEVICE}\")\n",
    "\n",
    "# 1. Load Data\n",
    "dataset = load_dataset(\"wmt14\", \"fr-en\")\n",
    "train_subset = dataset['train'].select(range(SUBSET_SIZE))\n",
    "valid_subset = dataset['validation'].select(range(1000))\n",
    "\n",
    "# 2. Build Vocab\n",
    "print(\"Building Vocabularies...\")\n",
    "vocab_en = Vocabulary(freq_threshold=1, max_size=80000)\n",
    "vocab_en.build_vocabulary([item['translation']['en'] for item in train_subset], vocab_en.tokenizer_eng)\n",
    "\n",
    "vocab_fr = Vocabulary(freq_threshold=1, max_size=80000)\n",
    "vocab_fr.build_vocabulary([item['translation']['fr'] for item in train_subset], vocab_fr.tokenizer_fr)\n",
    "\n",
    "print(f\"Unique English Words: {len(vocab_en)}\")\n",
    "print(f\"Unique French Words: {len(vocab_fr)}\")\n",
    "\n",
    "# 3. DataLoaders\n",
    "pad_idx = vocab_en.stoi[\"<PAD>\"]\n",
    "\n",
    "# Create the Dataset (No change here)\n",
    "train_dataset_obj = WMT14Dataset(train_subset, vocab_en, vocab_fr)\n",
    "\n",
    "# Initialize the Bucket Sampler\n",
    "# This replaces the 'shuffle=True' standard logic\n",
    "bucket_sampler = BucketBatchSampler(train_dataset_obj, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset_obj,\n",
    "    batch_sampler=bucket_sampler, # <--- Pass the custom sampler here\n",
    "    num_workers=0,\n",
    "    collate_fn=MyCollate(pad_idx)\n",
    ")\n",
    "\n",
    "print(\"Optimized DataLoader ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3659175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "TRAINING MODEL 1/5 (Seed: 1)\n",
      "====================\n",
      "Seed 1 | Epoch 1 | Loss: 6.406 | PPL: 605.33\n",
      "Seed 1 | Epoch 2 | Loss: 6.167 | PPL: 476.58\n",
      "Seed 1 | Epoch 3 | Loss: 6.074 | PPL: 434.44\n",
      "Seed 1 | Epoch 4 | Loss: 5.847 | PPL: 346.13\n",
      "Seed 1 | Epoch 5 | Loss: 5.607 | PPL: 272.27\n",
      "Seed 1 | Epoch 6 | Loss: 5.426 | PPL: 227.22\n",
      "Seed 1 | Epoch 7 | Loss: 5.279 | PPL: 196.23\n",
      "Seed 1 | Epoch 8 | Loss: 5.150 | PPL: 172.37\n",
      "Seed 1 | Epoch 9 | Loss: 5.051 | PPL: 156.11\n",
      "Seed 1 | Epoch 10 | Loss: 4.962 | PPL: 142.90\n",
      "Seed 1 | Epoch 11 | Loss: 4.877 | PPL: 131.19\n",
      "Seed 1 | Epoch 12 | Loss: 4.771 | PPL: 117.98\n",
      "Seed 1 | Epoch 13 | Loss: 4.698 | PPL: 109.69\n",
      "Seed 1 | Epoch 14 | Loss: 4.644 | PPL: 103.96\n",
      "Seed 1 | Epoch 15 | Loss: 4.586 | PPL: 98.12\n",
      "Seed 1 | Epoch 16 | Loss: 4.503 | PPL: 90.27\n",
      "Seed 1 | Epoch 17 | Loss: 4.454 | PPL: 86.00\n",
      "Seed 1 | Epoch 18 | Loss: 4.375 | PPL: 79.42\n",
      "Seed 1 | Epoch 19 | Loss: 4.308 | PPL: 74.32\n",
      "Seed 1 | Epoch 20 | Loss: 4.258 | PPL: 70.70\n",
      "--> Saved ensembel_model_seed_1.pt\n",
      "\n",
      "====================\n",
      "TRAINING MODEL 2/5 (Seed: 2)\n",
      "====================\n",
      "Seed 2 | Epoch 1 | Loss: 6.396 | PPL: 599.70\n",
      "Seed 2 | Epoch 2 | Loss: 6.180 | PPL: 482.93\n",
      "Seed 2 | Epoch 3 | Loss: 6.116 | PPL: 452.88\n",
      "Seed 2 | Epoch 4 | Loss: 6.053 | PPL: 425.53\n",
      "Seed 2 | Epoch 5 | Loss: 5.972 | PPL: 392.31\n",
      "Seed 2 | Epoch 6 | Loss: 5.811 | PPL: 333.99\n",
      "Seed 2 | Epoch 7 | Loss: 5.532 | PPL: 252.71\n",
      "Seed 2 | Epoch 8 | Loss: 5.364 | PPL: 213.61\n",
      "Seed 2 | Epoch 9 | Loss: 5.215 | PPL: 183.97\n",
      "Seed 2 | Epoch 10 | Loss: 5.087 | PPL: 161.92\n",
      "Seed 2 | Epoch 11 | Loss: 4.984 | PPL: 146.06\n",
      "Seed 2 | Epoch 12 | Loss: 4.912 | PPL: 135.86\n",
      "Seed 2 | Epoch 13 | Loss: 4.817 | PPL: 123.56\n",
      "Seed 2 | Epoch 14 | Loss: 4.717 | PPL: 111.82\n",
      "Seed 2 | Epoch 15 | Loss: 4.669 | PPL: 106.54\n",
      "Seed 2 | Epoch 16 | Loss: 4.591 | PPL: 98.61\n",
      "Seed 2 | Epoch 17 | Loss: 4.512 | PPL: 91.08\n",
      "Seed 2 | Epoch 18 | Loss: 4.457 | PPL: 86.25\n",
      "Seed 2 | Epoch 19 | Loss: 4.402 | PPL: 81.64\n",
      "Seed 2 | Epoch 20 | Loss: 4.360 | PPL: 78.25\n",
      "--> Saved ensembel_model_seed_2.pt\n",
      "\n",
      "====================\n",
      "TRAINING MODEL 3/5 (Seed: 3)\n",
      "====================\n",
      "Seed 3 | Epoch 1 | Loss: 6.402 | PPL: 603.22\n",
      "Seed 3 | Epoch 2 | Loss: 6.178 | PPL: 482.21\n",
      "Seed 3 | Epoch 3 | Loss: 6.120 | PPL: 454.85\n",
      "Seed 3 | Epoch 4 | Loss: 6.059 | PPL: 427.90\n",
      "Seed 3 | Epoch 5 | Loss: 5.961 | PPL: 388.03\n",
      "Seed 3 | Epoch 6 | Loss: 5.776 | PPL: 322.54\n",
      "Seed 3 | Epoch 7 | Loss: 5.549 | PPL: 257.10\n",
      "Seed 3 | Epoch 8 | Loss: 5.380 | PPL: 217.02\n",
      "Seed 3 | Epoch 9 | Loss: 5.217 | PPL: 184.35\n",
      "Seed 3 | Epoch 10 | Loss: 5.106 | PPL: 165.09\n",
      "Seed 3 | Epoch 11 | Loss: 4.992 | PPL: 147.30\n",
      "Seed 3 | Epoch 12 | Loss: 4.908 | PPL: 135.34\n",
      "Seed 3 | Epoch 13 | Loss: 4.823 | PPL: 124.29\n",
      "Seed 3 | Epoch 14 | Loss: 4.765 | PPL: 117.36\n",
      "Seed 3 | Epoch 15 | Loss: 4.678 | PPL: 107.58\n",
      "Seed 3 | Epoch 16 | Loss: 4.609 | PPL: 100.35\n",
      "Seed 3 | Epoch 17 | Loss: 4.546 | PPL: 94.29\n",
      "Seed 3 | Epoch 18 | Loss: 4.475 | PPL: 87.81\n",
      "Seed 3 | Epoch 19 | Loss: 4.420 | PPL: 83.07\n",
      "Seed 3 | Epoch 20 | Loss: 4.356 | PPL: 77.94\n",
      "--> Saved ensembel_model_seed_3.pt\n",
      "\n",
      "====================\n",
      "TRAINING MODEL 4/5 (Seed: 4)\n",
      "====================\n",
      "Seed 4 | Epoch 1 | Loss: 6.402 | PPL: 602.96\n",
      "Seed 4 | Epoch 2 | Loss: 6.167 | PPL: 476.75\n",
      "Seed 4 | Epoch 3 | Loss: 6.096 | PPL: 444.12\n",
      "Seed 4 | Epoch 4 | Loss: 5.914 | PPL: 370.08\n",
      "Seed 4 | Epoch 5 | Loss: 5.746 | PPL: 312.87\n",
      "Seed 4 | Epoch 6 | Loss: 5.622 | PPL: 276.50\n",
      "Seed 4 | Epoch 7 | Loss: 5.472 | PPL: 237.91\n",
      "Seed 4 | Epoch 8 | Loss: 5.355 | PPL: 211.69\n",
      "Seed 4 | Epoch 9 | Loss: 5.246 | PPL: 189.85\n",
      "Seed 4 | Epoch 10 | Loss: 5.157 | PPL: 173.66\n",
      "Seed 4 | Epoch 11 | Loss: 5.075 | PPL: 159.95\n",
      "Seed 4 | Epoch 12 | Loss: 5.004 | PPL: 148.96\n",
      "Seed 4 | Epoch 13 | Loss: 4.910 | PPL: 135.70\n",
      "Seed 4 | Epoch 14 | Loss: 4.831 | PPL: 125.28\n",
      "Seed 4 | Epoch 15 | Loss: 4.776 | PPL: 118.58\n",
      "Seed 4 | Epoch 16 | Loss: 4.712 | PPL: 111.26\n",
      "Seed 4 | Epoch 17 | Loss: 4.653 | PPL: 104.90\n",
      "Seed 4 | Epoch 18 | Loss: 4.616 | PPL: 101.13\n",
      "Seed 4 | Epoch 19 | Loss: 4.554 | PPL: 95.00\n",
      "Seed 4 | Epoch 20 | Loss: 4.506 | PPL: 90.59\n",
      "--> Saved ensembel_model_seed_4.pt\n",
      "\n",
      "====================\n",
      "TRAINING MODEL 5/5 (Seed: 5)\n",
      "====================\n",
      "Seed 5 | Epoch 1 | Loss: 6.411 | PPL: 608.38\n",
      "Seed 5 | Epoch 2 | Loss: 6.171 | PPL: 478.57\n",
      "Seed 5 | Epoch 3 | Loss: 6.073 | PPL: 434.19\n",
      "Seed 5 | Epoch 4 | Loss: 5.838 | PPL: 343.05\n",
      "Seed 5 | Epoch 5 | Loss: 5.625 | PPL: 277.26\n",
      "Seed 5 | Epoch 6 | Loss: 5.445 | PPL: 231.50\n",
      "Seed 5 | Epoch 7 | Loss: 5.302 | PPL: 200.77\n",
      "Seed 5 | Epoch 8 | Loss: 5.184 | PPL: 178.35\n",
      "Seed 5 | Epoch 9 | Loss: 5.077 | PPL: 160.32\n",
      "Seed 5 | Epoch 10 | Loss: 4.993 | PPL: 147.45\n",
      "Seed 5 | Epoch 11 | Loss: 4.904 | PPL: 134.81\n",
      "Seed 5 | Epoch 12 | Loss: 4.822 | PPL: 124.17\n",
      "Seed 5 | Epoch 13 | Loss: 4.766 | PPL: 117.45\n",
      "Seed 5 | Epoch 14 | Loss: 4.692 | PPL: 109.03\n",
      "Seed 5 | Epoch 15 | Loss: 4.616 | PPL: 101.13\n",
      "Seed 5 | Epoch 16 | Loss: 4.576 | PPL: 97.14\n",
      "Seed 5 | Epoch 17 | Loss: 4.504 | PPL: 90.41\n",
      "Seed 5 | Epoch 18 | Loss: 4.448 | PPL: 85.45\n",
      "Seed 5 | Epoch 19 | Loss: 4.392 | PPL: 80.80\n",
      "Seed 5 | Epoch 20 | Loss: 4.326 | PPL: 75.67\n",
      "--> Saved ensembel_model_seed_5.pt\n",
      "\n",
      "All 5 models trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- HYPERPARAMETERS ---\n",
    "INPUT_DIM = len(vocab_en)\n",
    "OUTPUT_DIM = len(vocab_fr)\n",
    "ENC_EMB_DIM = 1000\n",
    "DEC_EMB_DIM = 1000\n",
    "HID_DIM = 1000\n",
    "N_LAYERS = 4\n",
    "DROPOUT = 0.2\n",
    "N_EPOCHS = 20 \n",
    "CLIP = 5\n",
    "\n",
    "SEEDS = [1, 2, 3, 4, 5]\n",
    "\n",
    "def train_one_epoch(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# --- TRAINING LOOP FOR 5 MODELS ---\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*20}\")\n",
    "    print(f\"TRAINING MODEL {seed}/5 (Seed: {seed})\")\n",
    "    print(f\"{'='*20}\")\n",
    "    \n",
    "    # 1. Set Seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.mps.is_available(): torch.mps.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # 2. Initialize Fresh Model\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
    "    model.apply(init_weights) # Paper initialization\n",
    "    \n",
    "    # 3. Optimizer & Criterion\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "    \n",
    "    # 4. Train\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        loss = train_one_epoch(model, train_loader, optimizer, criterion, CLIP)\n",
    "        print(f\"Seed {seed} | Epoch {epoch+1} | Loss: {loss:.3f} | PPL: {math.exp(loss):.2f}\")\n",
    "        \n",
    "    # 5. Save Model\n",
    "    save_path = f\"ensembel_model_seed_{seed}.pt\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"--> Saved {save_path}\")\n",
    "\n",
    "print(\"\\nAll 5 models trained and saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55c31929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decode_ensemble(models_list, sentence, vocab_src, vocab_trg, beam_size=2, max_len=50, device='cpu'):\n",
    "    # Ensure models are in eval mode\n",
    "    for m in models_list: m.eval()\n",
    "    \n",
    "    # Prepare Input\n",
    "    if isinstance(sentence, str): tokens = vocab_src.tokenizer_eng(sentence)\n",
    "    else: tokens = [token.lower() for token in sentence]\n",
    "    \n",
    "    indices = [vocab_src.stoi.get(t, vocab_src.stoi[\"<UNK>\"]) for t in tokens]\n",
    "    indices = indices[::-1] # REVERSE\n",
    "    indices = [vocab_src.stoi[\"<SOS>\"]] + indices + [vocab_src.stoi[\"<EOS>\"]]\n",
    "    src_tensor = torch.LongTensor(indices).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encoder states for all models\n",
    "        initial_states = []\n",
    "        for m in models_list:\n",
    "            h, c = m.encoder(src_tensor)\n",
    "            initial_states.append((h, c))\n",
    "\n",
    "        hypotheses = [(0.0, [vocab_trg.stoi[\"<SOS>\"]], initial_states)]\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            all_candidates = []\n",
    "            for score, seq, states_list in hypotheses:\n",
    "                if seq[-1] == vocab_trg.stoi[\"<EOS>\"]:\n",
    "                    all_candidates.append((score, seq, states_list))\n",
    "                    continue\n",
    "                \n",
    "                last_token = torch.LongTensor([seq[-1]]).to(device)\n",
    "                \n",
    "                # Run all models and AVERAGE logits\n",
    "                avg_log_probs = None\n",
    "                new_states_list = []\n",
    "                for i, m in enumerate(models_list):\n",
    "                    prev_h, prev_c = states_list[i]\n",
    "                    pred, new_h, new_c = m.decoder(last_token, prev_h, prev_c)\n",
    "                    new_states_list.append((new_h, new_c))\n",
    "                    \n",
    "                    # --- FIX START ---\n",
    "                    # Squeeze the batch dimension: [1, vocab_size] -> [vocab_size]\n",
    "                    pred = pred.squeeze(0)\n",
    "                    # --- FIX END ---\n",
    "\n",
    "                    log_probs = F.log_softmax(pred, dim=0)\n",
    "                    if avg_log_probs is None: avg_log_probs = log_probs\n",
    "                    else: avg_log_probs += log_probs\n",
    "                \n",
    "                avg_log_probs = avg_log_probs / len(models_list)\n",
    "                top_k_probs, top_k_ids = avg_log_probs.topk(beam_size * 2)\n",
    "\n",
    "                for i in range(len(top_k_ids)):\n",
    "                    all_candidates.append((score + top_k_probs[i].item(), seq + [top_k_ids[i].item()], new_states_list))\n",
    "\n",
    "            hypotheses = sorted(all_candidates, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "            if all(h[1][-1] == vocab_trg.stoi[\"<EOS>\"] for h in hypotheses): break\n",
    "\n",
    "    best_seq = hypotheses[0][1]\n",
    "    decoded_words = [vocab_trg.itos[idx] for idx in best_seq]\n",
    "    if \"<SOS>\" in decoded_words: decoded_words.remove(\"<SOS>\")\n",
    "    if \"<EOS>\" in decoded_words: decoded_words = decoded_words[:decoded_words.index(\"<EOS>\")]\n",
    "    return \" \".join(decoded_words)\n",
    "\n",
    "# --- BLEU EVALUATOR ---\n",
    "def evaluate_ensemble(data_subset, models_list, vocab_src, vocab_trg, device, beam_size, n_gram=4):\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    print(f\"Evaluating Ensemble on {len(data_subset)} samples...\")\n",
    "    \n",
    "    for i, datum in enumerate(data_subset):\n",
    "        if (i+1)%50 == 0: print(f\"Processed {i+1}...\")\n",
    "        pair = datum['translation']\n",
    "        pred = beam_search_decode_ensemble(     \n",
    "                models_list, \n",
    "                pair['en'], \n",
    "                vocab_src, \n",
    "                vocab_trg, \n",
    "                beam_size, \n",
    "                max_len=50, # Optional: Explicitly set max_len here if you want\n",
    "                device=device\n",
    "            )\n",
    "        targets.append([pair['fr']])\n",
    "        predictions.append(pred)\n",
    "        \n",
    "    return bleu_score(predictions, targets, n_gram=n_gram).item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6be9cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ensemble Models...\n",
      "Loaded model_seed_1.pt\n",
      "Loaded model_seed_2.pt\n",
      "Loaded model_seed_3.pt\n",
      "Loaded model_seed_4.pt\n",
      "Loaded model_seed_5.pt\n",
      "\n",
      "--- Manual Ensemble Check ---\n",
      "Input: the cat sat on the mat\n",
      "Output: le applaudissements de la\n"
     ]
    }
   ],
   "source": [
    "# Load the 5 Saved Models\n",
    "ensemble_models = []\n",
    "print(\"Loading Ensemble Models...\")\n",
    "\n",
    "for seed in SEEDS:\n",
    "    # Re-instantiate architecture\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)\n",
    "    m = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
    "    \n",
    "    # Load weights\n",
    "    m.load_state_dict(torch.load(f\"ensembel_model_seed_{seed}.pt\", weights_only=True))\n",
    "    ensemble_models.append(m)\n",
    "    print(f\"Loaded model_seed_{seed}.pt\")\n",
    "\n",
    "# Sanity Check\n",
    "print(\"\\n--- Manual Ensemble Check ---\")\n",
    "test_sen = \"the cat sat on the mat\"\n",
    "print(f\"Input: {test_sen}\")\n",
    "print(f\"Output: {beam_search_decode_ensemble(ensemble_models, test_sen, vocab_en, vocab_fr, beam_size=2, device=DEVICE)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "799b6049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Ensemble on 1000 samples...\n",
      "Processed 50...\n",
      "Processed 100...\n",
      "Processed 150...\n",
      "Processed 200...\n",
      "Processed 250...\n",
      "Processed 300...\n",
      "Processed 350...\n",
      "Processed 400...\n",
      "Processed 450...\n",
      "Processed 500...\n",
      "Processed 550...\n",
      "Processed 600...\n",
      "Processed 650...\n",
      "Processed 700...\n",
      "Processed 750...\n",
      "Processed 800...\n",
      "Processed 850...\n",
      "Processed 900...\n",
      "Processed 950...\n",
      "Processed 1000...\n",
      "\n",
      "=================================\n",
      "FINAL ENSEMBLE BLEU SCORE with n_gram=1: 9.23\n",
      "=================================\n",
      "Evaluating Ensemble on 1000 samples...\n",
      "Processed 50...\n",
      "Processed 100...\n",
      "Processed 150...\n",
      "Processed 200...\n",
      "Processed 250...\n",
      "Processed 300...\n",
      "Processed 350...\n",
      "Processed 400...\n",
      "Processed 450...\n",
      "Processed 500...\n",
      "Processed 550...\n",
      "Processed 600...\n",
      "Processed 650...\n",
      "Processed 700...\n",
      "Processed 750...\n",
      "Processed 800...\n",
      "Processed 850...\n",
      "Processed 900...\n",
      "Processed 950...\n",
      "Processed 1000...\n",
      "\n",
      "=================================\n",
      "FINAL ENSEMBLE BLEU SCORE with n_gram=2: 2.76\n",
      "=================================\n",
      "Evaluating Ensemble on 1000 samples...\n",
      "Processed 50...\n",
      "Processed 100...\n",
      "Processed 150...\n",
      "Processed 200...\n",
      "Processed 250...\n",
      "Processed 300...\n",
      "Processed 350...\n",
      "Processed 400...\n",
      "Processed 450...\n",
      "Processed 500...\n",
      "Processed 550...\n",
      "Processed 600...\n",
      "Processed 650...\n",
      "Processed 700...\n",
      "Processed 750...\n",
      "Processed 800...\n",
      "Processed 850...\n",
      "Processed 900...\n",
      "Processed 950...\n",
      "Processed 1000...\n",
      "\n",
      "=================================\n",
      "FINAL ENSEMBLE BLEU SCORE with n_gram=3: 0.00\n",
      "=================================\n",
      "Evaluating Ensemble on 1000 samples...\n",
      "Processed 50...\n",
      "Processed 100...\n",
      "Processed 150...\n",
      "Processed 200...\n",
      "Processed 250...\n",
      "Processed 300...\n",
      "Processed 350...\n",
      "Processed 400...\n",
      "Processed 450...\n",
      "Processed 500...\n",
      "Processed 550...\n",
      "Processed 600...\n",
      "Processed 650...\n",
      "Processed 700...\n",
      "Processed 750...\n",
      "Processed 800...\n",
      "Processed 850...\n",
      "Processed 900...\n",
      "Processed 950...\n",
      "Processed 1000...\n",
      "\n",
      "=================================\n",
      "FINAL ENSEMBLE BLEU SCORE with n_gram=4: 0.00\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final BLEU Score\n",
    "n_grams_l = [1, 2, 3, 4]\n",
    "for _,n in enumerate(n_grams_l):\n",
    "    final_score = evaluate_ensemble(valid_subset, ensemble_models, vocab_en, vocab_fr, DEVICE, beam_size=2, n_gram=n)\n",
    "    print(f\"\\n=================================\")\n",
    "    print(f\"FINAL ENSEMBLE BLEU SCORE with n_gram={n}: {final_score:.2f}\")\n",
    "    print(f\"=================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
